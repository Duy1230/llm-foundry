# LLM-Foundry

A high-performance, modular training framework for LLM continued pre-training and fine-tuning. Built with state-of-the-art libraries including **Unsloth** for 2x faster training, **HuggingFace TRL** for training loops, and **Accelerate** for hardware abstraction.

## Features

- ğŸš€ **Ultra-fast training** with Unsloth optimization
- ğŸ”§ **Flexible configuration** via YAML files
- ğŸ“Š **Streaming data loading** for handling massive datasets
- ğŸ¯ **LoRA/QLoRA support** for efficient fine-tuning
- ğŸ“ˆ **WandB integration** for experiment tracking
- ğŸ”„ **Sequence packing** for improved training efficiency
- ğŸ§ª **Evaluation integration** with lm-evaluation-harness

## Project Structure

```
llm-foundry/
â”œâ”€â”€ configs/                  # YAML configurations for different stages
â”‚   â”œâ”€â”€ cpt/                  # Continued Pre-training configs
â”‚   â”‚   â””â”€â”€ llama3_cpt.yaml
â”‚   â””â”€â”€ sft/                  # Fine-tuning configs
â”‚       â””â”€â”€ mistral_chat.yaml
â”œâ”€â”€ data/                     # Data processing pipelines
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loaders.py            # Streaming logic
â”‚   â”œâ”€â”€ collators.py          # Dynamic padding & Sample Packing logic 
â”‚   â””â”€â”€ processors.py         # Chat template application & tokenization
â”œâ”€â”€ models/                   # Model definitions & PEFT wrappers
â”‚   â”œâ”€â”€ registry.py           # AutoModel loading logic
â”‚   â””â”€â”€ adapters.py           # LoRA/QLoRA injection using PEFT library
â”œâ”€â”€ engine/                   # Core training logic
â”‚   â”œâ”€â”€ trainer.py            # Abstracted training loop
â”‚   â”œâ”€â”€ objectives.py         # Loss functions
â”‚   â””â”€â”€ callbacks.py          # Logging and profiling hooks
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config_schema.py      # Configuration schema definitions
â”‚   â”œâ”€â”€ distributed.py        # FSDP/DeepSpeed setup helpers 
â”‚   â”œâ”€â”€ checkpointer.py       # Sharded checkpoint saving/loading management
â”‚   â””â”€â”€ eval.py               # Integration with lm-evaluation-harness
â””â”€â”€ scripts/
    â”œâ”€â”€ launch_train.py       # Entry point parsing YAML config
    â””â”€â”€ merge_adapter.py      # Post-training utility to merge LoRA weights
```

## Installation

```bash
pip install -r requirements.txt
```

## Configuration

The framework uses YAML configuration files to control all aspects of training. See `configs/` for examples:

- **CPT (Continued Pre-training)**: `configs/cpt/llama3_cpt.yaml`
- **SFT (Supervised Fine-tuning)**: `configs/sft/mistral_chat.yaml`

Configuration includes:
- Model and tokenizer settings
- Data loading parameters
- LoRA/QLoRA adapter configuration
- Training hyperparameters

## Usage

```bash
# Launch training with a config file
python scripts/launch_train.py --config_path configs/sft/mistral_chat.yaml
```

## Implementation Status

- âœ… **Phase 1**: Environment & Project Skeleton
- âœ… **Phase 2**: Configuration System
- â³ **Phase 3**: Data Pipeline (in progress)
- â³ **Phase 4**: Model & Adapter Logic
- â³ **Phase 5**: Core Engine
- â³ **Phase 6**: Utilities
- â³ **Phase 7**: Scripts & Entry Points
- â³ **Phase 8**: Testing & Verification

## License

[Add your license here]
